**Luke Hsu (To-Liang Hsu)**  
medical AI researcher / engineer  

ğŸ“ *B.S. Computer Science, Columbia University*  
ğŸ¥ *AI Center, China Medical University Hospital (CMUH), Taichung, Taiwan*  

---

### ğŸ§¬ About Me  
- ğŸ§  Researching **medical imaging AI** â€” brain tumor segmentation, pulmonary embolism detection, and physics-informed MRI simulation.
- ğŸ”¬ Currently exploring **physics-based and biologically grounded generative methods**. 
- ğŸ¤– Experience in **biosignal-driven robotics** and **assistive device control**.  

### ğŸ§¾ Selected Works
| Title | Venue |
|:------|:------|
| **Enhancing Brain Tumor Segmentation Generalizability via Pseudo-Labeling and Ratio-Adaptive Postprocessing** | MICCAI 2025 |
| **ChatEMG: Synthetic Data Generation for Robotic Hand Orthosis Control** | IEEE RA-L 2024 |
---

## ğŸ§  BraTS GoAT Challenge â€” *1st Place Solution* ğŸ†  (MICCAI 2025)
**Enhancing Brain Tumor Segmentation Generalizability via Pseudo-Labeling and Ratio-Adaptive Postprocessing**  
*To-Liang HsuÂ¹â‹†, Dang Khoa NguyenÂ¹â‹†, Pai LinÂ¹, Ching-Ting LinÂ¹, Wei-Chun WangÂ¹â‹†â‹†*  
Â¹ CMUH Artificial Intelligence Center, Taichung, Taiwan  
(â‹† Equal contribution, â‹†â‹† Corresponding author)  
*Accepted to MICCAI 2025 (in press, Lecture Notes in Computer Science, Springer)*  

ğŸ’» [**Project Website**](https://github.com/Lukehsu1999/BraTS-Multimodel-docker) &nbsp;|&nbsp;ğŸ“„ [**Paper (coming soon)**]() &nbsp;|&nbsp; ğŸ³ [**Official Docker Submission**](https://github.com/Lukehsu1999/BraTS-Multimodel-docker) &nbsp;|&nbsp; ğŸŒ [**BraTS 2025 Challenge Website**](https://www.synapse.org/Synapse:syn64153130/wiki/630130)

<p align="center">
  <img src="https://github.com/Lukehsu1999/Lukehsu1999/blob/main/MICCAI_Presentation.jpg" width="45%" valign="middle"/>
  <img src="https://github.com/Lukehsu1999/Lukehsu1999/blob/main/MICCAI_BraTS_Trophy.png" width="45%" valign="middle"/>
</p>

> **Summary:**  
> This work tackled one of the hardest problems in medical imaging â€” **cross-tumor generalization**.
> 
> I led the development of a **multi-model ensemble pipeline** that segments brain tumors across five distinct tumor types, even without knowing the tumor category in advance.  
>
> Our key innovations â€” **pseudo-label bootstrapping**, **ratio-adaptive postprocessing**, and **TumorSurfer multitask anatomy learning** â€” together improved robustness across tumor types and demographics, earning **1st place worldwide** at the *MICCAI 2025 BraTS GoAT Challenge*.

---

## ğŸ¦¾ ChatEMG: Synthetic EMG Data for Robotic Hand Orthosis (IEEE RA-L 2024)
**Published in [IEEE Robotics and Automation Letters (RA-L), 2024](https://arxiv.org/pdf/2406.12123)**  
*Jingxi XuÂ¹â‹†, Runsheng WangÂ¹â‹†, Siqi ShangÂ¹â‹†, Ava ChenÂ², Lauren WinterbottomÂ², To-Liang HsuÂ¹, Wenxi ChenÂ¹, Khondoker AhmedÂ¹, Pedro Leandro La RottaÂ¹, Xinyue ZhuÂ¹, Dawn M. NilsenÂ², Joel SteinÂ², Matei CiocarlieÂ¹*  
Â¹ Columbia University, Department of Mechanical Engineering  
Â² Columbia University Irving Medical Center  
(â‹† Equal contribution)

ğŸ’» [**Project Website**](https://jxu.ai/chatemg/) &nbsp;|&nbsp; ğŸ”— [**Paper (arXiv)**](https://arxiv.org/pdf/2406.12123) &nbsp;|&nbsp; ğŸ’» [**Official Reproducible Codebase**](https://github.com/jingxixu/chatemg)

[![ChatEMG Demonstration Video](https://github.com/Lukehsu1999/Lukehsu1999/blob/main/Screenshot%202024-11-15%20at%209.46.19%20PM.png)](https://www.youtube.com/watch?v=ozLbAGEkCug)

> **Summary:**  
> At Columbiaâ€™s **ROAM Lab**, I contributed to **ChatEMG**, a framework that generates **synthetic electromyography (EMG)** data to train models controlling a **robotic hand orthosis** for stroke rehabilitation.  
>  
> The project demonstrated how **language-conditioned generative models** can synthesize realistic biosignals for downstream control tasks â€” **reducing dependence on limited patient data** and enabling more **data-efficient training** of assistive robotic systems.  
>  
> ğŸ¤– *Published in IEEE Robotics and Automation Letters (RA-L), 2024.*


---

## ğŸŒ AskBobby: Social Service AI SMS Agent  
A social-impact project helping people in need locate **food, shelter, and health services** through SMS-powered AI.  
Partnership with **Foodbank for NYC** and 8 other non-profits organizations
Built with **Twilio**, **AWS Lambda**, and **LangChain** for real-time service discovery.  
*The system is currently offline, but check out the video below.*

ğŸ¥ [**Demo Video**](https://www.youtube.com/watch?v=wNDq_BOnTQ8)

<p align="center">
  <img src="https://github.com/Lukehsu1999/Lukehsu1999/blob/main/AskBobby_github_image.png" width="80%"/>
</p>

---

## ğŸ§° Tools & Technologies  
Python Â· PyTorch Â· MONAI Â· Docker Â· AWS Â· FastAPI Â· JavaScript Â· SQL Â· Git Â· C++

---

## ğŸ’¬ About Me  
ğŸ“ Columbia University | ğŸ¥ CMUH AI Center  
ğŸµ Pianist & double bassist | ğŸ€ Basketball enthusiast | ğŸ“š Lifelong learner  

ğŸ“« **Contact:** [LinkedIn](https://www.linkedin.com/in/to-liang-hsu) | [Email](mailto:lukehsu1999@gmail.com)
